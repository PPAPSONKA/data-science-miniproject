{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gesundheitsausgaben-Analyse\n",
    "\n",
    "## Projektübersicht\n",
    "Dieses Projekt analysiert Gesundheitsausgaben basierend auf verschiedenen Kategorien wie Finanzierungsquellen, Arten von Gesundheitsleistungen und Zeiträumen.\n",
    "\n",
    "Ziel ist es, Einblicke in die Entwicklung der Gesundheitskosten zu gewinnen und Muster zu identifizieren, die zukünftige Entscheidungen in der Gesundheitspolitik beeinflussen können.\n",
    "\n",
    "### **Projektziele:**\n",
    "1. **Datenbereinigung:** Aufbereitung der Rohdaten durch Entfernen unnötiger Spalten.\n",
    "2. **Datenanalyse:** Identifikation von Trends in den Gesundheitsausgaben.\n",
    "3. **Visualisierung:** Erstellung von Diagrammen für die Interpretation.\n",
    "4. **Berichterstellung:** Zusammenfassung der wichtigsten Erkenntnisse.\n",
    "\n",
    "### **Verwendete Datensätze:**\n",
    "Die Analyse basiert auf folgenden CSV-Dateien:\n",
    "- `OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0.csv` (Gesundheitsleistungen und -güter)\n",
    "- `OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0.csv` (Zeitreihen der Gesundheitsausgaben)\n",
    "- `OGD_gesausgaben01_HVD_HCHF_1_HEADER.csv` (Metadaten über Spaltenbezeichnungen)\n",
    "\n",
    "### **Projektstruktur:**\n",
    "- `data/` → Enthält die Anfangsdaten\n",
    "- `notebooks/` → Enthält das Jupyter Notebook\n",
    "- `output/` → Speichert bereinigte und aggregierte Daten\n",
    "- `scripts/` → Enthält wiederverwendbare Python-Funktionen"
   ],
   "id": "f4f42d087f0c97db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Libraries",
   "id": "640b60960cf578b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "id": "51cb6d1793b8361",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Datenanalyse\n",
    "\n",
    "1. **Hauptdatensatz:**  \n",
    "   - Datei: `OGD_gesausgaben01_HVD_HCHF_1.csv`  \n",
    "   - Enthält die eigentlichen Gesundheitsausgaben-Daten.  \n",
    "\n",
    "2. **Hilfsdatensätze:**  \n",
    "   - `OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0.csv` – Gesundheitsleistungen und -güter (HC)  \n",
    "   - `OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0.csv` – Zeitreihen der Gesundheitsausgaben  \n",
    "   - `OGD_gesausgaben01_HVD_HCHF_1_HEADER.csv` – Header-Metadaten zur Beschreibung der Spalten  \n",
    "\n",
    "#### Warum verwenden wir `;` als Delimiter?  \n",
    "\n",
    "Die bereitgestellten CSV-Dateien verwenden das Semikolon (`;`) als Trennzeichen (wir glauben um Verwechslungen mit Dezimalpunkten oder -kommas zu vermeiden)\n",
    "\n",
    "Daher muss beim Einlesen `delimiter=';'` explizit angegeben werden, um die Daten korrekt zu parsen.  \n"
   ],
   "id": "5c68bba4e46b4216"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_dfs(file_path=\"data\"):\n",
    "    dataframes = {}\n",
    "    for filename in os.listdir(file_path):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        file_path = os.path.join('data', filename)\n",
    "        df_ = pd.read_csv(file_path, delimiter=';')\n",
    "        df_name = filename.replace('.csv', '')\n",
    "        dataframes[df_name] = df_\n",
    "    return dataframes\n",
    "\n",
    "dataframes = read_dfs()\n",
    "df_main = dataframes['OGD_gesausgaben01_HVD_HCHF_1']\n",
    "df_hc = dataframes['OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0']\n",
    "df_time = dataframes['OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0']\n",
    "df_header = dataframes['OGD_gesausgaben01_HVD_HCHF_1_HEADER']\n",
    "\n",
    "def analyze_dataframe(df, name):\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    \n",
    "    print(\"\\nErste 5 Zeilen:\")\n",
    "    display(df.head())\n",
    "\n",
    "    # zufällige Stichprobe\n",
    "    print(\"\\nZufällige Stichprobe:\")\n",
    "    display(df.sample(5))\n",
    "\n",
    "    # Überblick über die Struktur des DataFrames\n",
    "    print(\"\\nDateninfo:\")\n",
    "    df.info()\n",
    "\n",
    "    # Deskriptive Statistiken\n",
    "    print(\"\\nDeskriptive Statistiken (numerische und kategoriale Werte):\")\n",
    "    display(df.describe())\n",
    "\n",
    "    # Unique Werte für jede Spalte (nur für kategorische Spalten sinnvoll)\n",
    "    print(\"\\nAnzahl eindeutiger Werte pro Spalte:\")\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].nunique()\n",
    "        print(f\"{col}: {unique_values} eindeutige Werte\")\n",
    "        # print(f\"  Werte: {df[col].unique()}\")  # unnötig zu viel output\n",
    "        \n",
    "    # ganz wichtig noch null werte!\n",
    "    print(f\"Fehlende Werte in {name}:\")\n",
    "    display(df.isnull().sum())\n",
    "\n",
    "for df_name, df in dataframes.items():\n",
    "    analyze_dataframe(df, df_name)"
   ],
   "id": "bca9a5d1ebc7425",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ergebnisse:  \n",
    "\n",
    "**1. Hauptdatensatz (Gesundheitsausgaben)**  \n",
    "- **Anzahl:** 729 Zeilen, 16 Spalten.  \n",
    "- **Datentypen:** Alle Spalten sind vom Typ `object`. Dies deutet darauf hin, dass möglicherweise numerische Werte als Text gespeichert wurden und eine Umwandlung notwendig sein könnte.  \n",
    "- **Fehlende Werte:** Keine fehlenden Werte festgestellt.  \n",
    "- **Mögliche Maßnahmen:** Überprüfung der Datenformate (z. B. Zahlen als Text) und mögliche Konvertierung in numerische Typen.  \n",
    "\n",
    "---\n",
    "\n",
    "**2. Gesundheitsleistungen und -güter (HC)**  \n",
    "- **Anzahl:** 46 Zeilen, 10 Spalten.  \n",
    "- **Fehlende Werte:**  \n",
    "  - Spalten `de_desc`, `de_link`, `en_desc`, `en_link`, `de_syn`, `en_syn` enthalten ausschließlich fehlende Werte und sollten entfernt werden.  \n",
    "  - Die Spalte `FK` weist 7 fehlende Werte auf, welche genauer überprüft werden müssen (z. B. Kategorie oder Obergruppe).  \n",
    "- **Mögliche Maßnahmen:**  \n",
    "  - Löschen irrelevanter Spalten mit ausschließlich fehlenden Werten.  \n",
    "  - Umgang mit fehlenden Werten in `FK` (Ersatz, Gruppierung oder Löschung).  \n",
    "\n",
    "---\n",
    "\n",
    "**3. Zeitreihen der Gesundheitsausgaben**  \n",
    "- **Anzahl:** 19 Zeilen, 10 Spalten.  \n",
    "- **Fehlende Werte:**  \n",
    "  - Die Spalte `Unnamed: 2` enthält nur `NaN`-Werte und sollte entfernt werden.  \n",
    "  - Weitere Spalten (`de_desc`, `de_link`, etc.) sind ebenfalls vollständig leer.  \n",
    "- **Datentypen:**  \n",
    "  - Die Spalten `name` und `en_name` sind als `int64` klassifiziert – sollte überprüft werden, ob dies korrekt ist oder in `string`/`category` geändert werden muss.  \n",
    "- **Mögliche Maßnahmen:**  \n",
    "  - Entfernen leerer Spalten.  \n",
    "  - Datentypen anpassen, falls erforderlich.  \n",
    "\n",
    "---\n",
    "\n",
    "**4. Header-Metadaten**  \n",
    "- **Anzahl:** 16 Zeilen, 10 Spalten.  \n",
    "- **Fehlende Werte:**  \n",
    "  - Unbenannte Spalten `Unnamed: 3` bis `Unnamed: 9` enthalten ausschließlich fehlende Werte und können entfernt werden.  \n",
    "- **Mögliche Maßnahmen:**  \n",
    "  - Entfernen leerer Spalten zur Reduzierung unnötiger Daten."
   ],
   "id": "56336aeaad7c6672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Datenbereinigung\n",
    "\n",
    "**Beobachtungen zur Anzahl fehlender Werte:**  \n",
    "\n",
    "- Der Hauptdatensatz enthält **keine** fehlenden Werte.  \n",
    "- Der HC-Datensatz weist mehrere Spalten mit vollständig fehlenden Werten auf.  \n",
    "- Unbenannte Spalten in den Zeitreihen- und Header-Daten enthalten nur NaN-Werte.  \n",
    "\n",
    "**TODO:**  \n",
    "- Entfernen unnötiger Spalten mit vollständig fehlenden Werten.  "
   ],
   "id": "d06b80b4f7a4bf08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_hc_cleaned = df_hc.drop(columns=['de_desc', 'de_link', 'en_desc', 'en_link', 'de_syn', 'en_syn'])\n",
    "df_time_cleaned = df_time.drop(columns=['Unnamed: 2', 'de_desc', 'de_link', 'en_desc', 'en_link', 'de_syn', 'en_syn'])\n",
    "df_header_cleaned = df_header.drop(columns=['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9'])\n",
    "\n",
    "print(\"Bereinigter HC-Datensatz:\")\n",
    "display(df_hc_cleaned.sample(5))\n",
    "\n",
    "print(\"Bereinigter Zeitreihen-Datensatz:\")\n",
    "display(df_time_cleaned.head())\n",
    "\n",
    "print(\"Bereinigter Header-Datensatz:\")\n",
    "display(df_header_cleaned.head())"
   ],
   "id": "3e4ca73f1819204e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FK-Spalte (Fremdschlüssel)\n",
    "\n",
    "Die FK-Spalte ist in einigen Zeilen leer (`NaN`), was darauf hindeutet, dass diese Zeilen übergeordnete Kategorien sind.  \n",
    "Unser Ziel ist es, die Hierarchie der Gesundheitsleistungen zu verstehen und ggf. geeignete Anpassungen vorzunehmen.\n",
    "\n",
    "**Zu untersuchende Aspekte:**\n",
    "\n",
    "1. Anzahl der `NaN`- und nicht-`NaN`-Werte in der FK-Spalte.  \n",
    "2. Identifikation der übergeordneten Kategorien anhand der FK-Spalte.  "
   ],
   "id": "d9874711a8604c1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Anzahl der fehlenden Werte in der FK-Spalte\n",
    "missing_fk = df_hc['FK'].isnull().sum()\n",
    "total_rows = len(df_hc)\n",
    "\n",
    "print(f\"Anzahl der fehlenden FK-Werte (Überkategorien): {missing_fk}\")\n",
    "print(f\"Anzahl der vorhandenen FK-Werte (Unterkategorien): {total_rows - missing_fk}\")\n",
    "\n",
    "# Anzeigen der Zeilen mit fehlender FK (Überkategorien)\n",
    "df_hc_missing_fk = df_hc[df_hc['FK'].isnull()]\n",
    "display(df_hc_missing_fk[['code', 'name']])\n",
    "\n",
    "# Anzeigen der Zeilen mit vorhandener FK (Unterkategorien)\n",
    "df_hc_with_fk = df_hc[df_hc['FK'].notnull()]\n",
    "display(df_hc_with_fk[['code', 'name', 'FK']].head(10))"
   ],
   "id": "3fc97e9dd8415355",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Ergebnisse der FK-Analyse:**  \n",
    "\n",
    "- Einträge mit fehlender FK markieren übergeordnete Kategorien.  \n",
    "- Einträge mit vorhandener FK verweisen auf ihre jeweilige Oberkategorie.  \n",
    "- Diese Hierarchie hilft uns, die Daten später besser zu analysieren und zu gruppieren.  \n",
    "\n",
    "**Nächster Schritt:**  \n",
    "- Erstellung einer neuen Spalte `Kategorieebene`, die zwischen übergeordneten und untergeordneten Kategorien unterscheidet.  \n",
    "- Falls sinnvoll, Speicherung einer hierarchischen Struktur für spätere Analysen oder Visualisierungen.  \n"
   ],
   "id": "3ea7530301dc8f10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Neue Spalte zur Kategorisierung hinzufügen (Über-/Unterkategorie)\n",
    "df_hc['Kategorieebene'] = df_hc['FK'].apply(lambda x: 'Oberkategorie' if pd.isnull(x) else 'Unterkategorie')\n",
    "\n",
    "# anzeigen der kartegorieebene\n",
    "display(df_hc[['code', 'name', 'FK', 'Kategorieebene']].head(15))\n",
    "\n",
    "# anzahl der Ober- und Unterkategorien anzeigen\n",
    "print(df_hc['Kategorieebene'].value_counts())\n"
   ],
   "id": "69eebb165c59bc04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bereinigung der Sprach- und Null-Spalten\n",
    "\n",
    "In den Datensätzen sind Spalten in deutscher und englischer Sprache enthalten.  \n",
    "Da die englischen Spalten redundant sind, werden sie entfernt.  \n",
    "Zusätzlich werden alle vollständig leeren Spalten identifiziert und aus den Daten gelöscht.\n",
    "\n",
    "#### Schritte:\n",
    "1. Entfernen der englischen Spalten.\n",
    "2. Identifikation von komplett leeren Spalten.\n",
    "3. Löschen der leeren Spalten, um die Datenqualität zu verbessern.\n",
    "4. Überprüfung der Datenstruktur nach der Bereinigung.\n"
   ],
   "id": "e34244086b76cdf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_df(dataframe, name):\n",
    "    print(f\"\\n--- Bereinigung für {name} ---\")\n",
    "\n",
    "    # 1. Englische Spalten entfernen (beginnen mit 'en_')\n",
    "    df_cleaned = df.drop(columns=[col for col in df.columns if col.startswith('en_')])\n",
    "\n",
    "    # 2. Vollständig leerer Spalten\n",
    "    empty_cols = df_cleaned.columns[df_cleaned.isnull().all()].tolist()\n",
    "    print(f\"Leere Spalten in {name}: {empty_cols}\")\n",
    "\n",
    "    # 3. Entfernen ovn leeren Spalten\n",
    "    df_cleaned.drop(columns=empty_cols, inplace=True)\n",
    "\n",
    "    # 4. Shape (Rows, Cols) nach Bereinigung\n",
    "    print(f\"Nach Bereinigung der englischen und leeren Spalten - {name}:\")\n",
    "    print(f\"{name} shape:\", df_cleaned.shape)\n",
    "\n",
    "    # 5. Speichern der bereinigten DataFrames\n",
    "    file_name = name + \"_corr.csv\"\n",
    "    df_cleaned.to_csv(f'data/corr/{file_name}', index=False, sep=';')\n",
    "    print(f\"Bereinigte Datei für {name} gespeichert als {file_name}\")\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    clean_df(df, name)"
   ],
   "id": "a70895070c3078b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Mergen der DataFrames und Datenvorbereitung\n",
    "\n",
    "Um die verschiedenen DataFrames mit relevanten Informationen zu kombinieren, haben wir alle DataFrames anhand des gemeinsamen Schlüssels `code` zusammengeführt. Dies stellt sicher, dass alle relevanten Daten in einem einzigen DataFrame vorliegen und keine Informationen verloren gehen.\n",
    "\n",
    "#### Schritte:\n",
    "1. **Mergen der DataFrames**:\n",
    "   - Wir haben die DataFrames `df_main`, `df_hc`, `df_time` und `df_header` mithilfe des gemeinsamen Schlüssels `code` zusammengeführt.\n",
    "   - Ein `left join` wurde verwendet, um sicherzustellen, dass alle Zeilen aus dem Hauptdatensatz (`df_main`) erhalten bleiben, und nur passende Zeilen aus den anderen DataFrames hinzugefügt werden.\n",
    "\n",
    "2. **Datenvorbereitung (Preprocessing)**:\n",
    "   - **Extraktion der numerischen Werte**: Alle numerischen Spalten (z.B. `int64`, `float64`) wurden extrahiert und in einer separaten CSV-Datei gespeichert.\n",
    "   - **Normalisierung der numerischen Werte**: Die numerischen Werte wurden mit einer Min-Max-Normalisierung skaliert und ebenfalls in einer separaten CSV-Datei gespeichert.\n",
    "   - **Extraktion der nominalen (kategorischen) Werte**: Alle nominalen Werte (z.B. `object`, `category`) wurden extrahiert und ebenfalls in einer separaten CSV-Datei gespeichert.\n",
    "\n",
    "#### Ergebnis:\n",
    "- **df_merged_num.csv**: Enthält die numerischen Werte aus allen zusammengeführten DataFrames.\n",
    "- **df_merged_norm.csv**: Enthält die normalisierten numerischen Werte.\n",
    "- **df_merged_nom.csv**: Enthält die nominalen (kategorischen) Werte.\n",
    "\n",
    "Das Mergen und die Datenvorbereitung sorgen dafür, dass alle relevanten Daten an einem Ort vorhanden sind und für die spätere Analyse bereitgestellt werden.\n"
   ],
   "id": "ae7d4e891ecccae8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Daten einlesen\n",
    "df_main = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_corr.csv', delimiter=';')\n",
    "df_hc = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0_corr.csv', delimiter=';')\n",
    "df_time = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0_corr.csv', delimiter=';')\n",
    "df_header = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_HEADER_corr.csv', delimiter=';')\n",
    "\n",
    "# 1. Mergen der DataFrames (angenommen, 'code' ist der gemeinsame Schlüssel)\n",
    "merged_df = pd.merge(df_hc_corr, df_time_corr, on='code', how='left')  # 'inner' für den Schnitt der beiden DataFrames\n",
    "final_merged_df = pd.merge(merged_df, df_header_corr, on='code', how='left')\n",
    "\n",
    "# Überprüfen der ersten Zeilen des finalen DataFrames\n",
    "display(final_merged_df)\n",
    "\n",
    "\n",
    "# Funktion zur Bereinigung und Speicherung der Daten\n",
    "def preprocess_and_save(df, filename_prefix):\n",
    "    # 1. Numerische Werte extrahieren\n",
    "    df_numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "    # Speichern der numerischen Werte in 'num.csv'\n",
    "    df_numeric.to_csv(f'{filename_prefix}_num.csv', index=False, sep=';')\n",
    "\n",
    "    # 2. Normalisierung der numerischen Werte (Min-Max Normalisierung)\n",
    "    df_normalized = (df_numeric - df_numeric.min()) / (df_numeric.max() - df_numeric.min())\n",
    "\n",
    "    # Speichern der normalisierten Werte in 'norm.csv'\n",
    "    df_normalized.to_csv(f'{filename_prefix}_norm.csv', index=False, sep=';')\n",
    "\n",
    "    # 3. Nominale Werte extrahieren\n",
    "    df_nominal = df.select_dtypes(include=['object', 'category'])\n",
    "\n",
    "    # Speichern der nominalen Werte in 'nom.csv'\n",
    "    df_nominal.to_csv(f'{filename_prefix}_nom.csv', index=False, sep=';')\n",
    "\n",
    "# Anwendung auf das gemergte DataFrame\n",
    "# preprocess_and_save(df_merged, 'df_merged')\n",
    "\n",
    "print(\"Daten wurden erfolgreich gespeichert.\")\n"
   ],
   "id": "589ae3eb9a2b4f8d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
