{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gesundheitsausgaben-Analyse\n",
    "\n",
    "## Projektübersicht\n",
    "Dieses Projekt analysiert Gesundheitsausgaben basierend auf verschiedenen Kategorien wie Finanzierungsquellen, Arten von Gesundheitsleistungen und Zeiträumen.\n",
    "\n",
    "Ziel ist es, Einblicke in die Entwicklung der Gesundheitskosten zu gewinnen und Muster zu identifizieren, die zukünftige Entscheidungen in der Gesundheitspolitik beeinflussen können.\n",
    "\n",
    "### Projektziele:\n",
    "1. **Datenbereinigung:** Aufbereitung der Rohdaten durch Entfernen unnötiger Spalten.\n",
    "2. **Datenanalyse:** Identifikation von Trends in den Gesundheitsausgaben.\n",
    "3. **Visualisierung:** Erstellung von Diagrammen für die Interpretation.\n",
    "4. **Berichterstellung:** Zusammenfassung der wichtigsten Erkenntnisse.\n",
    "\n",
    "### Verwendete Datensätze:\n",
    "Die Analyse basiert auf folgenden CSV-Dateien:\n",
    "- `OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0.csv` (Gesundheitsleistungen und -güter)\n",
    "- `OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0.csv` (Zeitreihen der Gesundheitsausgaben)\n",
    "- `OGD_gesausgaben01_HVD_HCHF_1_HEADER.csv` (Metadaten über Spaltenbezeichnungen)\n",
    "\n",
    "### Projektstruktur:\n",
    "- `data/` → Enthält die Anfangsdaten\n",
    "- `notebooks/` → Enthält das Jupyter Notebook\n",
    "- `output/` → Speichert bereinigte und aggregierte Daten\n",
    "- `scripts/` → Enthält wiederverwendbare Python-Funktionen"
   ],
   "id": "f4f42d087f0c97db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Libraries",
   "id": "640b60960cf578b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "id": "51cb6d1793b8361",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Cleanup (helps with debugging)\n",
    "import subprocess\n",
    "\n",
    "\n",
    "for dirname in \"data/corr\", \"data/prep\":\n",
    "    if os.path.exists(dirname):\n",
    "        subprocess.run([\"rm\", \"-rf\", dirname])\n",
    "    os.makedirs(dirname)\n"
   ],
   "id": "31c12ebe4167ebe3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Datenanalyse\n",
    "\n",
    "1. **Hauptdatensatz:**  \n",
    "   - Datei: `OGD_gesausgaben01_HVD_HCHF_1.csv`  \n",
    "   - Enthält die eigentlichen Gesundheitsausgaben-Daten.  \n",
    "\n",
    "2. **Hilfsdatensätze:**  \n",
    "   - `OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0.csv` – Gesundheitsleistungen und -güter (HC)  \n",
    "   - `OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0.csv` – Zeitreihen der Gesundheitsausgaben  \n",
    "   - `OGD_gesausgaben01_HVD_HCHF_1_HEADER.csv` – Header-Metadaten zur Beschreibung der Spalten  \n",
    "\n",
    "#### Warum verwenden wir `;` als Delimiter?  \n",
    "\n",
    "Die bereitgestellten CSV-Dateien verwenden das Semikolon (`;`) als Trennzeichen (wir glauben um Verwechslungen mit Dezimalpunkten oder -kommas zu vermeiden)\n",
    "\n",
    "Daher muss beim Einlesen `delimiter=';'` explizit angegeben werden, um die Daten korrekt zu parsen.\n",
    "\n",
    "Später im Projekt werden wir Beistrich (`','`) als Delimiter verwenden, um die Daten zu speichern, da dies der Standard in den meisten CSV-Dateien ist.\n"
   ],
   "id": "5c68bba4e46b4216"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_dataframe(df, name):\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "\n",
    "    print(\"\\nErste 5 Zeilen:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\nZufällige Stichprobe:\")\n",
    "    display(df.sample(5))\n",
    "\n",
    "    print(\"\\nDateninfo:\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\nStatistiken (numerische und kategoriale Werte):\")\n",
    "    display(df.describe())\n",
    "\n",
    "    # Unique Werte für jede Spalte (nur für kategorische Spalten sinnvoll)\n",
    "    print(\"\\nAnzahl eindeutiger Werte pro Spalte:\")\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].nunique()\n",
    "        print(f\"{col}: {unique_values} eindeutige Werte\")\n",
    "        # print(f\"  Werte: {df[col].unique()}\")  # unnötig zu viel output\n",
    "\n",
    "    # ganz wichtig noch null werte!\n",
    "    print(f\"Fehlende Werte in {name}:\")\n",
    "    display(df.isnull().sum())"
   ],
   "id": "bca9a5d1ebc7425",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataframes = {}\n",
    "for filename in os.listdir(\"data\"):\n",
    "    if not filename.endswith('.csv') and not filename.startswith('OGD_gesausgaben01_HVD_HCHF'): # SCHEISS auf die anderen dateien\n",
    "        continue\n",
    "    df_ = pd.read_csv(os.path.join(\"data\", filename), delimiter=';')\n",
    "    df_name = filename.replace('.csv', '')\n",
    "    dataframes[df_name] = df_\n",
    "\n",
    "df_main = dataframes['OGD_gesausgaben01_HVD_HCHF_1']\n",
    "df_hc = dataframes['OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0']\n",
    "df_time = dataframes['OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0']\n",
    "df_header = dataframes['OGD_gesausgaben01_HVD_HCHF_1_HEADER']\n",
    "\n",
    "for df_name, df in dataframes.items():\n",
    "    analyze_dataframe(df, df_name)"
   ],
   "id": "962b588f21465b9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ergebnisse:  \n",
    "\n",
    "**1. Hauptdatensatz (Gesundheitsausgaben)**  \n",
    "- **Anzahl:** 729 Zeilen, 16 Spalten.  \n",
    "- **Datentypen:** Alle Spalten sind vom Typ `object`. Dies deutet darauf hin, dass möglicherweise numerische Werte als Text gespeichert wurden und eine Umwandlung notwendig sein könnte.  \n",
    "- **Fehlende Werte:** Keine fehlenden Werte festgestellt.  \n",
    "- **Mögliche Maßnahmen:** Überprüfung der Datenformate (z. B. Zahlen als Text) und mögliche Konvertierung in numerische Typen.  \n",
    "\n",
    "---\n",
    "\n",
    "**2. Gesundheitsleistungen und -güter (HC)**  \n",
    "- **Anzahl:** 46 Zeilen, 10 Spalten.  \n",
    "- **Fehlende Werte:**  \n",
    "  - Spalten `de_desc`, `de_link`, `en_desc`, `en_link`, `de_syn`, `en_syn` enthalten ausschließlich fehlende Werte und sollten entfernt werden.  \n",
    "  - Die Spalte `FK` weist 7 fehlende Werte auf, welche genauer überprüft werden müssen (z. B. Kategorie oder Obergruppe).  \n",
    "- **Mögliche Maßnahmen:**  \n",
    "  - Löschen irrelevanter Spalten mit ausschließlich fehlenden Werten.  \n",
    "  - Umgang mit fehlenden Werten in `FK` (Ersatz, Gruppierung oder Löschung).  \n",
    "\n",
    "---\n",
    "\n",
    "**3. Zeitreihen der Gesundheitsausgaben**  \n",
    "- **Anzahl:** 19 Zeilen, 10 Spalten.  \n",
    "- **Fehlende Werte:**  \n",
    "  - Die Spalte `Unnamed: 2` enthält nur `NaN`-Werte und sollte entfernt werden.  \n",
    "  - Weitere Spalten (`de_desc`, `de_link`, etc.) sind ebenfalls vollständig leer.  \n",
    "- **Datentypen:**  \n",
    "  - Die Spalten `name` und `en_name` sind als `int64` klassifiziert – sollte überprüft werden, ob dies korrekt ist oder in `string`/`category` geändert werden muss.  \n",
    "- **Mögliche Maßnahmen:**  \n",
    "  - Entfernen leerer Spalten.  \n",
    "  - Datentypen anpassen, falls erforderlich.  \n",
    "\n",
    "---\n",
    "\n",
    "**4. Header-Metadaten**  \n",
    "- **Anzahl:** 16 Zeilen, 10 Spalten.  \n",
    "- **Fehlende Werte:**  \n",
    "  - Unbenannte Spalten `Unnamed: 3` bis `Unnamed: 9` enthalten ausschließlich fehlende Werte und können entfernt werden.  \n",
    "- **Mögliche Maßnahmen:**  \n",
    "  - Entfernen leerer Spalten zur Reduzierung unnötiger Daten."
   ],
   "id": "56336aeaad7c6672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Konvertierung der Daten in numerische Werte",
   "id": "355fc0dca0bac9df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TWO DAYS AND 10 CHIPS PACKETS AND 50 COFFES LATER WE DISCOVERED THAT THE DATA IS NOT NUMERIC AND WE NEED TO REPLACE , WITH . AND CONVERT TO NUMERIC\n",
    "# DHIS BULLSHIT IS NOT NUMERIC\n",
    "# df_main.iloc[:, 2:] = df_main.iloc[:, 2:].replace(',', '.', regex=True).apply(pd.to_numeric)\n",
    "# THIS IS NOT WORKING\n",
    "# WE JUST SAVE THE DATAFRAME TO CSV AND READ IT AGAIN\n",
    "\n",
    "# F*ck it, we save the data to csv and read it again\n",
    "\n",
    "df_main.replace(',', '.', regex=True).to_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_corr.csv', index=False)  # replace , with . for numeric conversion\n",
    "df_main = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_corr.csv') # read and check if it worked\n",
    "df_main.info()"
   ],
   "id": "d9f493dd022304ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bereinigung der Sprach- und Null-Spalten\n",
    "\n",
    "In den Datensätzen sind Spalten in deutscher und englischer Sprache enthalten.  \n",
    "Da die englischen Spalten redundant sind, werden sie entfernt.  \n",
    "Zusätzlich werden alle vollständig leeren Spalten aus den Daten gelöscht.\n"
   ],
   "id": "e34244086b76cdf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_df(dataframe, name):\n",
    "    print(f\"\\n--- Bereinigung für {name} ---\")\n",
    "\n",
    "    # 1. Englische Spalten entfernen (beginnen mit 'en_')\n",
    "    df_cleaned = df.drop(columns=[col for col in df.columns if col.startswith('en_')])\n",
    "\n",
    "    # 2. Vollständig leerer Spalten\n",
    "    empty_cols = df_cleaned.columns[df_cleaned.isnull().all()].tolist()\n",
    "    print(f\"Leere Spalten in {name}: {empty_cols}\")\n",
    "\n",
    "    # 3. Entfernen ovn leeren Spalten\n",
    "    df_cleaned.drop(columns=empty_cols, inplace=True)\n",
    "\n",
    "    # 4. Shape (Rows, Cols) nach Bereinigung\n",
    "    print(f\"Nach Bereinigung der englischen und leeren Spalten - {name}:\")\n",
    "    print(f\"{name} shape:\", df_cleaned.shape)\n",
    "\n",
    "    # 5. Speichern der bereinigten DataFrames\n",
    "    file_name = name + \"_corr.csv\"\n",
    "    df_cleaned.to_csv(f'data/corr/{file_name}', index=False)\n",
    "    print(f\"Bereinigte Datei für {name} gespeichert als {file_name}\")\n",
    "\n",
    "del dataframes['OGD_gesausgaben01_HVD_HCHF_1']  # remove main dataframe (already cleaned)\n",
    "for name, df in dataframes.items():\n",
    "    clean_df(df, name)"
   ],
   "id": "a70895070c3078b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ersetzung von Codes durch Namen\n",
    "\n",
    "Nach der ersten Datenbereinigung werden die Codes in den Spalten `C-ZEITGES-0` und `C-HCGES-0`  \n",
    "durch verständliche Namen ersetzt. Dies geschieht mit den Mapping-Tabellen aus den  \n",
    "Header- und Gesundheitsleistungsdateien.\n",
    "\n",
    "Bevor das getan werden kann, mappen wir die Oberkategorien in der HCGES Datei auf die Unterkategorien. \n",
    "\n",
    "Nach der Ersetzung speichern wir die aktualisierten Daten für die weitere Verarbeitung. Außerdem löschen wir die unnötigen Files.\n"
   ],
   "id": "62846e627f987e88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_main_corr = df_main # copy the main dataframe, don't need to read it again\n",
    "df_hc_corr = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_C-HCGES-0_corr.csv')\n",
    "df_time_corr = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_C-ZEITGES-0_corr.csv')\n",
    "df_header_corr = pd.read_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_HEADER_corr.csv')"
   ],
   "id": "f52ad21cbf2654cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --- 1. Mapping für 'C-HCGES-0' mit df_hc_corr ---\n",
    "hc_mapping = df_hc_corr.set_index('code')['name'].to_dict()\n",
    "df_main_corr['C-HCGES-0'] = df_main_corr['C-HCGES-0'].apply(lambda x: hc_mapping.get(x, x))\n",
    "\n",
    "# --- 2. Mapping für 'C-ZEITGES-0' mit df_time_corr ---\n",
    "time_mapping = df_time_corr.set_index('code')['name'].to_dict()\n",
    "df_main_corr['C-ZEITGES-0'] = df_main_corr['C-ZEITGES-0'].apply(lambda x: time_mapping.get(x, x))\n",
    "\n",
    "# --- 3. Mapping der Spaltennamen mit df_header_corr ---\n",
    "header_mapping = df_header_corr.set_index('code')['name'].to_dict()\n",
    "df_main_corr.rename(columns=header_mapping, inplace=True)\n",
    "\n",
    "df_main_corr.to_csv('data/corr/OGD_gesausgaben01_HVD_HCHF_1_corr.csv', index=False)"
   ],
   "id": "1f56c90943507cbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Datenvorbereitung und Speicherung\n",
    "\n",
    "Nach der Vorverarbeitung der Daten werden die bereinigten Daten in verschiedene Kategorien unterteilt und separat gespeichert.  \n",
    "\n",
    "##### 1. Numerische Werte  \n",
    "- Enthält alle Spalten mit numerischen Daten (z. B. `int64`, `float64`).  \n",
    "- Diese Daten werden extrahiert und in einer separaten Datei gespeichert.  \n",
    "- **Dateiname:** `num.csv`  \n",
    "\n",
    "##### 2. Nominale Werte  \n",
    "- Enthält alle kategorialen und textbasierten Daten (z. B. `category`, `object`).  \n",
    "- Diese Werte werden extrahiert und separat gespeichert.  \n",
    "- **Dateiname:** `nom.csv`  \n",
    "\n",
    "##### 3. Normalisierte Werte  \n",
    "- Für eine bessere Vergleichbarkeit und Skalierung werden die numerischen Daten normalisiert.  \n",
    "- Die Min-Max-Normalisierung wird verwendet, um die Werte in den Bereich von 0 bis 1 zu bringen.  \n",
    "- **Dateiname:** `norm.csv`\n"
   ],
   "id": "2662ce478753d9ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Numerische Werte extrahieren\n",
    "df_main_corr.info()\n",
    "df_numeric = df_main_corr.select_dtypes(include=['int64', 'float64'])\n",
    "df_numeric.to_csv('data/prep/num.csv', index=False)\n",
    "\n",
    "# Nominale Werte extrahieren (kategorische und objektbasierte Spalten)\n",
    "df_nominal = df_main_corr.select_dtypes(include=['category', 'object'])\n",
    "df_nominal.to_csv('data/prep/nom.csv', index=False)\n",
    "\n",
    "# Normalisierung der numerischen Werte (Min-Max-Normalisierung)\n",
    "df_normalized = (df_numeric - df_numeric.min()) / (df_numeric.max() - df_numeric.min())\n",
    "df_normalized.to_csv('data/prep/norm.csv', index=False)"
   ],
   "id": "cc9b98e635ce5557",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
